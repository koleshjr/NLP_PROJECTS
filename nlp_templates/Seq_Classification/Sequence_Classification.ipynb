{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UArp4poE-Urx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sequence Classification"
      ],
      "metadata": {
        "id": "gN-1Wu9b-gDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install The Necessary Linraries"
      ],
      "metadata": {
        "id": "oG-qR8f3-zwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets optuna sentencepiece evaluate wandb huggingface-hub\n",
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "IUIHVbuX-ypU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import The Necessary Libraries"
      ],
      "metadata": {
        "id": "IzJpiLCm-_nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import wandb\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback"
      ],
      "metadata": {
        "id": "2jm-JTiw_CIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config"
      ],
      "metadata": {
        "id": "W6ERBKds_w8Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cfg:\n",
        "  trial = 1\n",
        "  path = \"\"\n",
        "  project_name = \"\"\n",
        "  model_name = \"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  seed = 42\n",
        "  train_file = \"\"\n",
        "  test_file = \"\"\n",
        "  label_mappings = None\n",
        "  batch_size = 128\n",
        "  max_length = 512\n",
        "  num_classes = None\n",
        "\n",
        "  #training params\n",
        "  num_epochs = 4\n",
        "  learning_rate = 1e-06\n",
        "  warmup_steps = 500\n",
        "  early_stopping_patience = 30\n",
        "  lr_scheduler = \"cosine\"\n",
        "  eval_strategy =\"steps\"\n",
        "  steps = 250\n",
        "  accum_steps = 8\n",
        "\n",
        "  #trial attributes\n",
        "  project_name = f\"{model_name}-{num_epochs}_trial_{trial}\"\n",
        "\n",
        "  #submission\n",
        "  predict_num = 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "33r9i0XV_ysd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Wandb: Track your Trial Runs"
      ],
      "metadata": {
        "id": "0iKZJF3pAwW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()\n",
        "wandb.init(project=CFG.project_name)\n",
        "%env WANDB_LOG_MODEL=true   #log every trained model"
      ],
      "metadata": {
        "id": "htzSVvsUAy4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reproducibility"
      ],
      "metadata": {
        "id": "wqbA4ZslA34a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_random_seed(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
        "\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "set_random_seed(CFG.seed)\n",
        "transformers.set_seed(CFG.seed)"
      ],
      "metadata": {
        "id": "qGUXsYEfA5Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load The Datasets"
      ],
      "metadata": {
        "id": "RDZzvI1FA9ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(Cfg.path + Cfg.train_file)\n",
        "test = pd.read_csv(Cfg.path + Cfg.test_file)\n",
        "display(train.head(), test.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "JA4fqcAFA_bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df, text_col, target_col= None,id_col= None ):\n",
        "    # Rename columns if necessary\n",
        "    if text_col != 'inputs':\n",
        "        df.rename(columns={text_col: 'inputs'}, inplace=True)\n",
        "    if target_col:\n",
        "        if target_col != 'target':\n",
        "            df.rename(columns={target_col: 'label'}, inplace=True)\n",
        "    if id_col:\n",
        "        if id_col != 'id':\n",
        "            df.rename(columns={id_col: 'id'}, inplace=True)\n",
        "\n",
        "\n",
        "    df['Character Count'] = df['inputs'].apply(lambda x: len(str(x)))\n",
        "    print(\"The longest input has a length of\", df['Character Count'].max())\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train = preprocess(df=train,text_col='Word',target_col='Pos',id_col='Id')\n",
        "test = preprocess(df=test,text_col='Word',target_col='Pos',id_col='Id')\n"
      ],
      "metadata": {
        "id": "9jN-xzuEBQGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train['label'] = le.fit_transform(train['label'])\n",
        "CFG.label_mappings = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(CFG.label_mappings)\n"
      ],
      "metadata": {
        "id": "8kWVjfhTB7bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup The Tokenizer"
      ],
      "metadata": {
        "id": "i0OnW__RB_wB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokz = AutoTokenizer.from_pretrained(CFG.model_nm)\n",
        "sep = tokz.sep_token\n",
        "\n",
        "def tokenize(x): return tokz(x[\"inputs\"],truncation=True, padding=True, max_length=CFG.max_length)"
      ],
      "metadata": {
        "id": "lUcAzvXkCBMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Validation"
      ],
      "metadata": {
        "id": "6geDSfwxCI_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folds = StratifiedKFold(n_splits=5)\n",
        "train['fold'] = -1\n",
        "for i,(train_index, test_index) in enumerate(folds.split(train,train['label'])):\n",
        "    train.loc[test_index,'fold'] = i"
      ],
      "metadata": {
        "id": "F_92XxTHCLN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric"
      ],
      "metadata": {
        "id": "otlFMbnHCTYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    f1_macro = f1_score(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1_macro\": f1_macro}\n",
        "\n"
      ],
      "metadata": {
        "id": "O5BBvJdxCcE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build The Train Function"
      ],
      "metadata": {
        "id": "8t7J62cADbfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train():\n",
        "    all_valid_losses = []\n",
        "    for fold in range(5):\n",
        "        print(f\"Fold {fold} ----------------------------------- TRAINING -----------------------------------\")\n",
        "        train_df = train[train['fold'] != fold]\n",
        "        valid_df = train[train['fold'] == fold]\n",
        "\n",
        "        train_dataset = Dataset.from_pandas(train_df)\n",
        "        valid_dataset = Dataset.from_pandas(valid_df)\n",
        "\n",
        "        train_tokenized_df = train_dataset.map(tokenize, batched=True)\n",
        "        valid_tokenized_df = valid_dataset.map(tokenize, batched=True)\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(CFG.model_nm, num_labels=CFG.num_classes, hidden_dropout_prob=CFG.dropout).to(CFG.device)\n",
        "\n",
        "\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir = project_name,\n",
        "            learning_rate = Cfg.learning_rate,\n",
        "            warmup_steps = Cfg.warmup_steps,\n",
        "            per_device_train_batch_size = Cfg.batch_size,\n",
        "            per_device_eval_batch_size = Cfg.batch_size,\n",
        "            weight_decay = 0.01,\n",
        "            evaluation_strategy= Cfg.eval_strategy,\n",
        "            logging_strategy = Cfg.eval_strategy,\n",
        "            logging_steps = Cfg.steps,\n",
        "            save_strategy = Cfg.eval_strategy,\n",
        "            save_steps = Cfg.steps,\n",
        "            eval_steps = Cfg.steps,\n",
        "            log_level = \"warning\",\n",
        "            fp16 = True,\n",
        "            gradient_accumulation_steps = Cfg.accum_steps,\n",
        "            save_total_limit = 1,\n",
        "            metric_for_best_model = \"accuracy\"\n",
        "            )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model = model,\n",
        "            compute_metrics = compute_metrics,\n",
        "            train_dataset = train_tokenized_df,\n",
        "            eval_dataset = valid_tokenized_df,\n",
        "            tokenizer = tokz,\n",
        "            callbacks = [early_stopping_callback]\n",
        "            )\n",
        "\n",
        "        trainer.train()\n",
        "        print(f\"Fold {fold} ----------------------------------- VALIDATING -----------------------------------\")\n",
        "        valid_preds = trainer.predict(valid_tokenized_df)\n",
        "        valid_preds = softmax(valid_preds.predictions)\n",
        "        np.save(f\"outputs/fold{fold}/valid_preds.npy\", valid_preds)\n",
        "        trainer.save_model(f\"{fold}_{project_name}\")\n",
        "\n",
        "        # Calculate log loss for the current fold\n",
        "        valid_labels = valid_tokenized_df['label']\n",
        "        valid_loss = log_loss(valid_labels, valid_preds)\n",
        "        all_valid_losses.append(valid_loss)\n",
        "\n",
        "        del trainer, model\n",
        "\n",
        "    # Calculate overall valid_loss\n",
        "    overall_valid_loss = sum(all_valid_losses) / len(all_valid_losses)\n",
        "    print(f\"Overall Valid Loss: {overall_valid_loss}\")\n"
      ],
      "metadata": {
        "id": "GrgKnHQcDefF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "TwDAoMKkJrAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inference():\n",
        "  test_dataset = Dataset.from_pandas(test)\n",
        "  test_tokenized_df = test_dataset.map(tokenize, batched=True)\n",
        "  test_preds = []\n",
        "\n",
        "  for fold in range(5):\n",
        "    loaded_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        f\"{fold}_{project_name}\",\n",
        "        num_labels = Cfg.num_labels\n",
        "    )\n",
        "\n",
        "    loaded_tokenizer = AutoTokenizer.from_pretrained(\n",
        "        f\"{fold}_{project_name}\",\n",
        "    )\n",
        "\n",
        "    test_args = TrainingArguments(\n",
        "      output_dir = CFG.path,\n",
        "      do_train = False,\n",
        "      do_predict = True,\n",
        "      per_device_eval_batch_size = CFG.batch_size,\n",
        "      dataloader_drop_last = False\n",
        "      )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model = loaded_model,\n",
        "        args = test_args,\n",
        "        compute_metrics = compute_metrics\n",
        "    )\n",
        "\n",
        "    test_results = trainer.predict(test_tokenized_df)\n",
        "\n",
        "    if Cfg.predict_num == 1:\n",
        "        result = test_results.predictions.argmax(axis=1)\n",
        "        test_preds.append(result)\n",
        "        result = pd.DataFrame(result, columns=['pred'])\n",
        "        result['Id'] = test['id']\n",
        "        result = result[['Id', 'pred']]\n",
        "\n",
        "        # Reverse the dictionary to map values to labels\n",
        "        name_le_mapping = {v: k for k, v in CFG.label_mappings.items()}\n",
        "        # Map the 'pred' values to their string labels\n",
        "        result['pred'] = result['pred'].map(name_le_mapping)\n",
        "        display(result.head())\n",
        "\n",
        "        result.to_csv(f\"{fold}_{project_name}.csv\")\n",
        "\n",
        "    else:\n",
        "        # Assuming you have the predicted probabilities in test_results\n",
        "        result = pd.DataFrame(test_results.predictions, columns=CFG.label_mappings.values())\n",
        "        result['Id'] = test['id']\n",
        "        display(result.head())\n",
        "\n",
        "        result.to_csv(f\"{fold}_{project_name}_probs.csv\", index=False)\n",
        "\n",
        "  # Save the average of the 5 folds\n",
        "  if CFG.predict_num != 1:\n",
        "      avg_preds = sum(test_preds) / len(test_preds)\n",
        "      avg_result = pd.DataFrame(avg_preds, columns=CFG.label_mappings.values())\n",
        "      avg_result['Id'] = test['id']\n",
        "      display(avg_result.head())\n",
        "\n",
        "      avg_result.to_csv(f\"average_{project_name}.csv\", index=False)\n",
        "\n",
        "  else:\n",
        "      # Find the most occurring label\n",
        "      most_occurred_label = test_preds.mode(axis=0).iloc[0]\n",
        "      result = pd.DataFrame(most_occurred_label, columns=['pred'])\n",
        "      result['Id'] = test['id']\n",
        "\n",
        "      # Reverse the dictionary to map values to labels\n",
        "      name_le_mapping = {v: k for k, v in CFG.label_mappings.items()}\n",
        "      # Map the 'pred' values to their string labels\n",
        "      result['pred'] = result['pred'].map(name_le_mapping)\n",
        "      display(result.head())\n",
        "\n",
        "      result.to_csv(f\"mode_{project_name}.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "ckBpjFFwJsEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run It"
      ],
      "metadata": {
        "id": "3gHVnMFaOMVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"__name__\" == \"__main__\":\n",
        "  train()\n",
        "  inference()"
      ],
      "metadata": {
        "id": "0OVHVpWFONa0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}